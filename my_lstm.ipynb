{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{':', 'а', 'l', '\"', 'й', 'ц', 'с', 'к', '-', 'j', 'ь', 'ч', 'г', '+', '_', 'q', '{', '<', '*', '%', 'ж', 'х', 'в', ')', '/', 'i', 'f', 'b', 'g', ' ', '3', 'p', 'л', 'е', ',', 'ъ', ';', '\\\\', 'ф', 'щ', 'c', 'a', 'k', 'ш', '8', '7', '0', 'z', 'б', 'у', 'r', 'ы', 'я', 'ю', '!', '6', 'e', '2', 'н', 'u', '=', 'м', '4', 'd', 'y', 'x', 'з', 't', 'э', 'п', '1', 'д', 'р', '.', 'ё', '~', 'и', 'm', '5', '9', 'n', 'v', '(', 'w', 's', 'h', 'о', 'o', 'т', '№'}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n"
     ]
    }
   ],
   "source": [
    "%run FuzzyLogic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 15)\n",
      "(0,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-693-54d04bfdc83b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "data = [\"Ты пидор!\", \"Знай, Ты пидор!\", \"Знай, пидор!\"]\n",
    "data = [s.lower() for s in data];\n",
    "\n",
    "look_back = 7\n",
    "batch_size = 32\n",
    "num_lstm = 5\n",
    "\n",
    "x = []\n",
    "for s in data:\n",
    "    sx = []\n",
    "    for c in list(s):\n",
    "        vec = onehot_encoded[char_to_int[c]]\n",
    "        sx.append(vec)\n",
    "    x.append(sx)\n",
    "    \n",
    "dataframe = pandas.DataFrame.from_records(x)\n",
    "dataset = dataframe.values\n",
    "#dataset = dataset.astype('float32')\n",
    "    \n",
    "print(dataset.shape)\n",
    "\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "\n",
    "train = dataset[:train_size];\n",
    "test = dataset[train_size:]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(train, look_back)\n",
    "    \n",
    "print(trainX.shape)\n",
    "    \n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], look_back, trainX.shape[2]))\n",
    "trainY = numpy.reshape(trainY, (trainY.shape[0], trainY.shape[1]))\n",
    "\n",
    "testX = numpy.reshape(testX, (testX.shape[0], look_back, testX.shape[2]))\n",
    "testY = numpy.reshape(testY, (testY.shape[0], testY.shape[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 7, 90)\n",
      "(36, 90)\n",
      "[[[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "(36, 7, 90)\n",
      "(36, 90)\n"
     ]
    }
   ],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 7\n",
    "batch_size = 1\n",
    "num_lstm = 5\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "#trainX = numpy.reshape(trainX, (trainX.shape[0], look_back, trainX.shape[2]))\n",
    "trainY = numpy.reshape(trainY, (trainY.shape[0], trainY.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], look_back, testX.shape[2]))\n",
    "testY = numpy.reshape(testY, (testY.shape[0], testY.shape[1]))\n",
    "\n",
    "print(trainX)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 7, 90)\n",
      "(20, 90)\n",
      "Epoch 1/20\n",
      " - 67s - loss: 0.0110\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.0110\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.0107\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.0105\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.0104\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.0104\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.0103\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.0103\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.0102\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.0102\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.0101\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.0100\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.0099\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.0098\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.0096\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.0095\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.0094\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.0093\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.0092\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.0091\n",
      "(20, 7, 90)\n",
      "(20, 90)\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.0090\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.0089\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.0087\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.0086\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.0082\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.0082\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.0081\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.0078\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.0076\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.0075\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.0073\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.0071\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.0066\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.0063\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.0065\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.0060\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.0060\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.0056\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.0053\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.0051\n",
      "(11, 7, 90)\n",
      "(11, 90)\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.0129\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.0124\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.0120\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.0112\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.0109\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.0105\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.0093\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.0089\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.0084\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.0079\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.0077\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.0070\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.0069\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.0063\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.0057\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.0052\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.0044\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.0032\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.0028\n",
      "(7, 7, 90)\n",
      "(7, 90)\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.0159\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.0115\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.0098\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.0088\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.0082\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.0078\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.0061\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.0037\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.0012\n",
      "Epoch 10/20\n",
      " - 0s - loss: 5.4353e-04\n",
      "Epoch 11/20\n",
      " - 0s - loss: 3.1417e-04\n",
      "Epoch 12/20\n",
      " - 0s - loss: 1.9328e-04\n",
      "Epoch 13/20\n",
      " - 0s - loss: 1.2353e-04\n",
      "Epoch 14/20\n",
      " - 0s - loss: 8.0571e-05\n",
      "Epoch 15/20\n",
      " - 0s - loss: 5.3489e-05\n",
      "Epoch 16/20\n",
      " - 0s - loss: 3.5750e-05\n",
      "Epoch 17/20\n",
      " - 0s - loss: 2.4053e-05\n",
      "Epoch 18/20\n",
      " - 0s - loss: 1.6339e-05\n",
      "Epoch 19/20\n",
      " - 0s - loss: 1.1249e-05\n",
      "Epoch 20/20\n",
      " - 0s - loss: 7.8924e-06\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "data = [\"Ты пидор!Знай,Ты пидор!Пидор\", \"Ты пидор!Знай,Ты пидор!Пидор\", \"Ms1 SM1MS1SM11MS MS\", \n",
    "        \"MS1MS1MS1MS1MS1\"]\n",
    "data = [s.lower() for s in data];\n",
    "\n",
    "look_back = 7\n",
    "batch_size = 1\n",
    "num_lstm = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(90, return_sequences=True, input_shape=(look_back, 90)))\n",
    "for i in range(2, num_lstm):\n",
    "    model.add(LSTM(90, return_sequences=True))\n",
    "model.add(LSTM(90))\n",
    "model.add(Dense(90, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "for s in data: \n",
    "    x = []\n",
    "    for c in list(s):\n",
    "        vec = onehot_encoded[char_to_int[c]]\n",
    "        x.append(vec)\n",
    "\n",
    "    dataframe = pandas.DataFrame.from_records(x)\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    \n",
    "    # normalize the dataset\n",
    "#    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#    dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "#    train_size = int(len(dataset) * 0.67)\n",
    "    train = dataset\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    \n",
    "    trainX = numpy.reshape(trainX, (trainX.shape[0], look_back, trainX.shape[2]))\n",
    "    trainY = numpy.reshape(trainY, (trainY.shape[0], trainY.shape[1]))\n",
    "    \n",
    "    print(trainX.shape)\n",
    "    print(trainY.shape)\n",
    "    \n",
    "    model.fit(trainX, trainY, epochs=20, batch_size=batch_size, shuffle=False, verbose=2)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.12 RMSE\n",
      "р\n",
      "s\n",
      "1\n",
      "s\n",
      "s\n",
      "s\n",
      ",\n",
      ",\n",
      "д\n",
      "д\n",
      "п\n",
      "о\n",
      "о\n",
      "s\n",
      "р\n",
      "s\n",
      "1\n",
      "s\n",
      "s\n",
      "s\n",
      "Train Score: 0.12 RMSE\n",
      "р\n",
      "s\n",
      "1\n",
      "s\n",
      "s\n",
      "s\n",
      ",\n",
      ",\n",
      "д\n",
      "д\n",
      "п\n",
      "о\n",
      "о\n",
      "s\n",
      "р\n",
      "s\n",
      "1\n",
      "s\n",
      "s\n",
      "s\n",
      "Train Score: 0.14 RMSE\n",
      "s\n",
      "1\n",
      "m\n",
      "1\n",
      "s\n",
      "s\n",
      "m\n",
      "s\n",
      "1\n",
      "m\n",
      "1\n",
      "Train Score: 0.00 RMSE\n",
      "s\n",
      "1\n",
      "m\n",
      "s\n",
      "1\n",
      "m\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "for s in data:\n",
    "    x = []\n",
    "    for c in list(s):\n",
    "        vec = onehot_encoded[char_to_int[c]]\n",
    "        x.append(vec)\n",
    "\n",
    "    dataframe = pandas.DataFrame.from_records(x)\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    \n",
    "    # normalize the dataset\n",
    "    #scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    #dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "    \n",
    "    train = dataset\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    \n",
    "    trainX = numpy.reshape(trainX, (trainX.shape[0], look_back, trainX.shape[2]))\n",
    "    trainY = numpy.reshape(trainY, (trainY.shape[0], trainY.shape[1]))\n",
    "    \n",
    "    trainPredict = model.predict(trainX, batch_size=1)\n",
    "    \n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform(trainY)\n",
    "    \n",
    "    trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    \n",
    "    for p in trainPredict:\n",
    "        max_i = 0\n",
    "        max_v = 0\n",
    "        for i, v in enumerate(p.tolist()):\n",
    "            if v > max_v:\n",
    "                max_i = i\n",
    "                max_v = v\n",
    "        print(int_to_char[max_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 60s - loss: 0.0108\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.0102\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.0100\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.0099\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.0098\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.0098\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.0098\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.0100\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.0106\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.0095\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.0100\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.0099\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.0096\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.0099\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.0096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a0c24828>"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(90, return_sequences=True, batch_input_shape=(batch_size, look_back, 90), stateful=True))\n",
    "for i in range(2, num_lstm):\n",
    "    model.add(LSTM(90, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(90))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=batch_size, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 36 samples. Batch size: 32.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-650-a711d700fec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtestPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# invert predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                                  \u001b[0;34m'divided by the batch size. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' samples. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                                  'Batch size: ' + str(batch_size) + '.')\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `predict_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 36 samples. Batch size: 32."
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX, batch_size=1)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in trainPredict:\n",
    "    max_i = 0\n",
    "    max_v = 0\n",
    "    for i, v in enumerate(p.tolist()):\n",
    "        if v > max_v:\n",
    "            max_i = i\n",
    "            max_v = v\n",
    "    print(int_to_char[max_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)jk \n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
